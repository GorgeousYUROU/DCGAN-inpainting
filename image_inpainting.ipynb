{"cells":[{"metadata":{"colab_type":"text","id":"view-in-github"},"cell_type":"markdown","source":"# 导入包"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"colab_type":"code","id":"Daz4EN2qNu27","outputId":"1f837095-c126-498e-cfb9-12732e0dba0d","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\nimport numpy as np\ntf.enable_eager_execution()\nimport matplotlib.pyplot as plt\nimport os\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 构造生成器和判别器"},{"metadata":{},"cell_type":"markdown","source":"## 构造生成器类\n"},{"metadata":{},"cell_type":"markdown","source":"![avatar](http://ppfijofch.bkt.clouddn.com/net1.PNG)"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"AuqiX32cONPo","outputId":"23f96a89-25bb-4e02-893a-b953ed6f54ee","trusted":true},"cell_type":"code","source":"class Generator(tf.keras.Model):\n  def __init__(self):\n    super(Generator, self).__init__()\n    \n    #全连接层\n    self.fc1 = tf.keras.layers.Dense(units=4*4*512, activation=None)\n    \n    # BN + ReLU\n    self.bn1 = tf.keras.layers.BatchNormalization(scale=False)\n    self.activation1 = tf.keras.layers.Activation(activation='relu')\n    \n    # 转置卷积层1  转置卷积为shape：(batch_size, 8, 8, 256)\n    self.transp_conv1 = tf.keras.layers.Conv2DTranspose(256, 5, strides=2, padding=\"SAME\", activation=None)\n    \n    # BN + ReLU\n    self.bn2 = tf.keras.layers.BatchNormalization(scale=False)\n    self.activation2= tf.keras.layers.Activation(activation='relu')\n    \n    # 转置卷积层2  转置卷积为shape：(batch_size, 16, 16, 128)\n    self.transp_conv2 = tf.keras.layers.Conv2DTranspose(128, 5, strides=2, padding=\"SAME\", activation=None)\n    \n    # BN + ReLU\n    self.bn3 = tf.keras.layers.BatchNormalization(scale=False)\n    self.activation3= tf.keras.layers.Activation(activation='relu')\n    \n   # 转置卷积层3  转置卷积为shape：(batch_size, 32, 32, 64)\n    self.transp_conv3 = tf.keras.layers.Conv2DTranspose(64, 5, strides=2, padding=\"SAME\", activation=None)\n    \n    # BN + ReLU\n    self.bn4 = tf.keras.layers.BatchNormalization(scale=False)\n    self.activation4= tf.keras.layers.Activation(activation='relu')\n\n    \n    # 转置卷积层4  转置卷积为shape：(batch_size, 64, 64, 3)\n    self.transp_conv4 = tf.keras.layers.Conv2DTranspose(3, 5, strides=2, padding=\"SAME\", activation=None)\n    self.out = tf.keras.layers.Activation(activation='tanh')\n  #call函数让类可以作为函数被调用  \n  def call(self,z, is_training):\n\n    fc1 = self.fc1(z)\n    fc1_reshaped = tf.reshape(fc1, (-1,4,4,512))\n\n    bn1 = self.bn1(fc1_reshaped, training=is_training)\n    activation1 = self.activation1(bn1)\n\n    trans_conv1 = self.transp_conv1(activation1) \n    bn2 = self.bn2(trans_conv1, training=is_training)\n    activation2 = self.activation2(bn2)\n\n    transp_conv2 = self.transp_conv2(activation2) \n    bn3 = self.bn3(transp_conv2, training=is_training)\n    activation3 = self.activation3(bn3)\n    \n    transp_conv3 = self.transp_conv3(activation3) \n    bn4 = self.bn4(transp_conv3, training=is_training)\n    activation4 = self.activation4(bn4)\n    \n    transp_conv4 = self.transp_conv4(activation4) \n    output = self.out(transp_conv4)\n    \n    return output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 构造判别器类"},{"metadata":{},"cell_type":"markdown","source":"![avatar](http://ppfijofch.bkt.clouddn.com/net2.PNG)"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"vhqWL2DTZSPO","outputId":"72326866-ed12-435a-9c65-d70611fe4a40","trusted":true},"cell_type":"code","source":"\nclass Discriminator(tf.keras.Model):\n  def __init__(self, alpha):\n    super(Discriminator, self).__init__()\n    # 卷积层1  卷积为shape：(batch_size, 32, 32, 64)\n    self.conv1 = tf.keras.layers.Conv2D(64, 5, strides=2, padding='SAME', activation=None)\n    self.activation1 = tf.keras.layers.LeakyReLU(alpha=alpha)\n    \n    # 卷积层2  卷积为shape：(batch_size, 16, 16, 128)\n    self.conv2 = tf.keras.layers.Conv2D(128, 5, strides=2, padding='SAME', activation=None)\n    self.bn1 = tf.keras.layers.BatchNormalization(scale=False)\n    self.activation2 = tf.keras.layers.LeakyReLU(alpha=alpha)\n    \n    # 卷积层3  卷积为shape：(batch_size, 8, 8, 256)\n    self.conv3 = tf.keras.layers.Conv2D(256, 5, strides=2, padding='SAME', activation=None)\n    self.bn2 = tf.keras.layers.BatchNormalization(scale=False)\n    self.activation3 = tf.keras.layers.LeakyReLU(alpha=alpha)\n    \n    # 卷积层4  卷积为shape：(batch_size, 4, 4, 512)\n    self.conv4 = tf.keras.layers.Conv2D(512, 5, strides=2, padding='SAME', activation=None)\n    self.bn3 = tf.keras.layers.BatchNormalization(scale=False)\n    self.activation4 = tf.keras.layers.LeakyReLU(alpha=alpha)\n    \n    # 把输入拉成一维向量  卷积为shape：(batch_size*4*4*512)\n    self.flatten = tf.keras.layers.Flatten()\n    self.fc1 = tf.keras.layers.Dense(units=1, activation=None)\n    self.out = tf.keras.layers.Activation(activation='sigmoid')\n  \n  def call(self, inputs, is_training):\n\n    conv1 = self.conv1(inputs)\n    activation1 = self.activation1(conv1)\n    \n    conv2 = self.conv2(activation1)\n    bn1 = self.bn1(conv2, training=is_training)\n    activation2 = self.activation2(bn1)\n    \n    conv3 = self.conv3(activation2)\n    bn2 = self.bn2(conv3, training=is_training)\n    activation3 = self.activation3(bn2)\n    \n    conv4 = self.conv4(activation3)\n    bn3 = self.bn3(conv4, training=is_training)\n    activation4 = self.activation4(bn3)\n    \n    flat = self.flatten(activation4)\n    logits = self.fc1(flat)\n    out = self.out(logits)\n    return out, logits","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 设置参数"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"g52OgUeWYU6T","outputId":"150ac1c1-808a-453b-bc7d-53f948569f22","trusted":true},"cell_type":"code","source":"\nz_dim = 100 #输入噪声维度\nlearning_rate = 0.0002 \n\nalpha = 0.2 #leakyRelu的斜率\nbeta1 = 0.5 #Adm优化器的衰减率\nsmooth=0.1\n\nbatch_size = 128\n\ncounter = 0 #训练次数\nepoch=10 #迭代次数\nimage_size=108 #裁剪图像的大小\nimage_shape=[64,64,3]\nsample_num = 64 #测试图像的数量","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"Ehm_VlwuVLGy","outputId":"11df0729-acc2-4f65-c8e6-d4c6c9a6ab0a","trusted":true},"cell_type":"code","source":"generator_net = Generator()\ndiscriminator_net = Discriminator(alpha=alpha)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 定义代价函数"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"Ju55l68je7lq","outputId":"18df5169-b3fd-4ea4-d821-f3f28a06991c","trusted":true},"cell_type":"code","source":"def discriminator_loss(d_logits_real, d_logits_fake, smooth=0.1):\n    \n    #判别器两个代价函数\n    #输入真图片，判断逼近1\n    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real) * (1 - smooth)))\n\n    #输入假图片，判断逼近0\n    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_model_fake)))\n\n    d_loss = d_loss_real + d_loss_fake\n    return d_loss","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"4qPjaoYh3j-v","outputId":"408ced86-0334-4dd4-8832-dcd356e1b5f8","trusted":true},"cell_type":"code","source":"def generator_loss(d_logits_fake, d_model_fake):\n  \n    #生成器一个代价函数\n    #输入假图片，迷惑判别器判断逼近1\n    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake)))\n    return g_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 定义优化器"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"11WPYNiD1Tdw","outputId":"d706743d-90d7-4e17-fbd4-2094f542430e","trusted":true},"cell_type":"code","source":"global_counter = tf.train.get_or_create_global_step()\ngenerator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\ndiscriminator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 处理数据和数据显示"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"wbjnfUSI-Mf4","outputId":"1243b661-4672-4b1d-d9d8-12721748112b","trusted":true},"cell_type":"code","source":"from glob import glob\n#数据集\n##获取所有图片路径\ndatas=glob(os.path.join('../input/img_align_celeba/img_align_celeba/','*.jpg'))","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"colab_type":"code","id":"BzLwoZUWelPL","outputId":"83e42253-e5c5-4e88-fb62-df2d5b5207f8","trusted":true},"cell_type":"code","source":"def display_images(dataset, figsize=(4,4), denomalize=True):\n    fig, axes = plt.subplots(3, 3, sharex=True, sharey=True, figsize=figsize,)\n    for ii, ax in enumerate(axes.flatten()):\n        img = dataset[ii,:,:,:]\n        if denomalize:\n            img = ((img + 1)*255 / 2).astype(np.uint8) # Scale back to 0-255\n        \n        ax.imshow(img)\n      \n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.misc\nimport numpy as np\nfrom PIL import Image\nimport skimage\nfrom glob import glob\nimport imageio\n\n# Helpers for image handling\ndef get_image(image_path, image_size, is_crop=True):\n    return transform(imread(image_path), image_size, is_crop)\n\ndef save_images(images, image_path):\n    for imgindex in range(images.shape[0]):\n        imageio.imsave(image_path+str(imgindex)+'.jpg',images[imgindex])\n\ndef imread(path):\n    return imageio.imread(path).astype(np.float)\n\ndef transform(image, npx=64, is_crop=True):\n    # npx : # of pixels width/height of image\n    if is_crop:\n        cropped_image = center_crop(image, npx)\n    else:\n        cropped_image = image\n    return np.array(cropped_image)/127.5 - 1.\n\ndef center_crop(x, crop_h, crop_w=None, resize_w=64): \n    if crop_w is None:\n        crop_w = crop_h\n    h, w = x.shape[:2]\n    j = int(round((h - crop_h)/2.))\n    i = int(round((w - crop_w)/2.))\n    return skimage.transform.resize(x[j:j+crop_h, i:i+crop_w], [resize_w, resize_w])\n\n#def imsave(images, size, path):\n #   return scipy.misc.imsave(path, merge(images, size))\n\ndef inverse_transform(images):\n    return (images+1.)/2.\n\ndef merge(images, size):\n    h, w = images.shape[1], images.shape[2]\n    img = np.zeros((h * size[0], w * size[1], 3))\n\n    for idx, image in enumerate(images):\n        i = idx % size[1]\n        j = idx / size[1]\n        img[j*h:j*h+h, i*w:i*w+w, :] = image\n\n    return img\n\n\ndef convert_to_lower_resolution():\n    images=glob(os.path.join('cars_train\\cars_train/','*.jpg'))\n    i=0\n    size=108,108\n    for image in images:\n\n        im=Image.open(image)\n        im_resized=im.resize(size,Image.ANTIALIAS)\n        im_resized.save(\"cars_train/\"+str(i)+'.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 运行模型"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 生成测试噪声输入\nfake_input_test = tf.random_uniform(shape=(sample_num, z_dim),\n                                 minval=-1.0, maxval=1.0, dtype=tf.float32)\n\nnum_batch = (int)(len(datas)/batch_size)\ntemp = 1\nfor i in range(epoch):\n    #随机打乱数据\n    np.random.shuffle(datas)\n    for ii in range(num_batch):\n        #生成以batch为单位的随机噪声\n        fake_input = tf.random_uniform(shape=(batch_size, z_dim),\n                                     minval=-1.0, maxval=1.0, dtype=tf.float32)\n        \n        #因为数据过大，采用以batch为单位处理数据集的做法\n        batch_files=datas[ii*batch_size:(ii+1)*batch_size]\n        batch=[get_image(batch_file,image_size,is_crop=True) for batch_file in batch_files]\n        batch_images=np.reshape(np.array(batch).astype(np.float32),[batch_size]+image_shape)\n\n        with tf.GradientTape(persistent=True) as tape:\n    \n            # 运行生成器\n            g_model = generator_net(fake_input, is_training=True)\n\n            # 输入真图片运行判别器\n            d_model_real, d_logits_real = discriminator_net(batch_images, is_training=True)\n\n            # 输入假图片运行判别器\n            d_model_fake, d_logits_fake = discriminator_net(g_model, is_training=True)\n\n            # 计算生成器的损失\n            gen_loss = generator_loss(d_logits_fake, d_model_fake)\n\n            # 计算判别器的损失\n            dis_loss = discriminator_loss(d_logits_real, d_logits_fake, smooth)\n\n            \n\n            if counter % 1000 == 0:\n                generated_samples = generator_net(fake_input_test, is_training=False)\n                display_images(generated_samples.numpy())\n            \n            #为变量计算梯度\n            discriminator_grads = tape.gradient(dis_loss, discriminator_net.variables)\n            generator_grads = tape.gradient(gen_loss, generator_net.variables)\n            \n            #进行梯度更新\n            discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator_net.variables), global_step=global_counter)\n            generator_optimizer.apply_gradients(zip(generator_grads, generator_net.variables), global_step=global_counter)\n            generator_optimizer.apply_gradients(zip(generator_grads, generator_net.variables), global_step=global_counter)\n            if i>5 :\n                generator_optimizer.apply_gradients(zip(generator_grads, generator_net.variables), global_step=global_counter)\n                \n            counter += 1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_input_test = tf.random_uniform(shape=(9, z_dim),\n                                 minval=-1.0, maxval=1.0, dtype=tf.float32)\ngenerated_samples = generator_net(fake_input_test, is_training=False)\ndisplay_images(generated_samples.numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# 增加样本集"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_num=64\nsample_files=datas[0:sample_num]\nsample=[get_image(sample_file,image_size,is_crop=True) for sample_file in sample_files]\nsample_images=np.reshape(np.array(sample).astype(np.float32),[sample_num]+image_shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 增加图像修复代价函数"},{"metadata":{"trusted":true},"cell_type":"code","source":"def complete_Inpainting_loss(g_loss, mask, G, images,lam):\n  \n    \n    #真图片未破损部分与假图片未破损部分的生成损失\n    contextual_loss = tf.reduce_sum(\n            tf.contrib.layers.flatten(\n                tf.abs(tf.multiply(mask,G) - tf.multiply(mask, images))), 1)\n    #感知信息损失（保证全局结构性）\n    perceptual_loss=g_loss\n    complete_loss = contextual_loss + lam*perceptual_loss\n    return complete_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 生成MASK矩阵"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_Mask(batch_size):\n    scale=0.25 #遮挡部分占全部图片的百分比\n    #遮挡图片的MASK矩阵\n    mask=np.ones([batch_size]+image_shape).astype(np.float32)\n    l=int(image_shape[0]*scale)\n    u=int(image_shape[0]*(1.0-scale))\n    mask[:,l:u,l:u,:]=0.0\n\n\n    #取出破损部分的MASK矩阵\n    scale=0.25\n    imask=np.zeros([batch_size]+image_shape).astype(np.float32)\n    l=int(image_shape[0]*scale)\n    u=int(image_shape[0]*(1.0-scale))\n    imask[:,l:u,l:u,:]=1.0\n    \n    return mask,imask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 运行模型"},{"metadata":{"trusted":true},"cell_type":"code","source":"lam=0.1\nnIndex = 500 #图像的迭代次数\nbeta1=0.9\nbeta2=0.9\neps=1e-9\nlr=0.01\nbatch_size =64\nsample_mask,sample_imask = generate_Mask(sample_num)\nmask,imask = generate_Mask(batch_size)\n# 生成测试噪声输入\nfake_input_test = tf.random_uniform(shape=(sample_num, z_dim),\n                                 minval=-1.0, maxval=1.0, dtype=tf.float32)\n\nnum_batch = (int)(len(datas)/batch_size)\n\nnp.random.shuffle(datas)\nfor i in range(num_batch):\n    #生成以batch为单位的随机噪声\n    fake_input = tf.random_uniform(shape=(batch_size, z_dim),\n                                     minval=-1.0, maxval=1.0, dtype=tf.float32)\n        \n    #因为数据过大，采用以batch为单位处理数据集的做法\n    batch_files=datas[i*batch_size:(i+1)*batch_size]\n    batch=[get_image(batch_file,image_size,is_crop=True) for batch_file in batch_files]\n    batch_images=np.reshape(np.array(batch).astype(np.float32),[batch_size]+image_shape)\n    \n    m = 0\n    v = 0\n    for ii in range(nIndex):\n        with tf.GradientTape(persistent=True) as tape:\n            tape.watch(fake_input)\n            # 运行生成器\n            g_model = generator_net(fake_input, is_training=False)\n\n             # 输入假图片运行判别器\n            d_model_fake, d_logits_fake = discriminator_net(g_model, is_training=False)\n\n            # 计算生成器的损失\n            gen_loss = generator_loss(d_logits_fake, d_model_fake)\n            complete_loss = complete_Inpainting_loss(gen_loss, mask, g_model, batch_images,lam)\n            g = tape.gradient(target=complete_loss, sources=fake_input)\n            \n            \n        if ii % 50 == 0:\n            #生成假图片\n            generated_samples = generator_net(fake_input, is_training=False)\n            #提取真图片对应假图片的破损部分\n            fake_part = np.multiply(generated_samples,sample_imask)\n            #破损原图\n            real_part = np.multiply(batch_images,sample_mask)\n            #通道拼接得到原图\n            inpainting_sample = np.add(fake_part,real_part)\n            plt.subplot(121)\n            plt.xticks([])\n            plt.yticks([])\n            plt.imshow(generated_samples[0].numpy())\n            plt.subplot(122)\n            plt.imshow(inpainting_sample[0])\n            plt.xticks([])\n            plt.yticks([])\n            \n            plt.show()\n\n        #对单张图片(fake_input)进行更新\n        m_prev = np.copy(m)\n        v_prev = np.copy(v)\n        \n        m = beta1 * m_prev + (1 - beta1) * g[0]\n        v = beta2 * v_prev + (1 - beta2) * np.multiply(g[0], g[0])\n        m_hat = m / (1 - beta1 ** (ii + 1))\n        v_hat = v / (1 - beta2 ** (ii + 1))\n        fake_input += - np.true_divide(lr * m_hat, (np.sqrt(v_hat) + eps))\n        fake_input = tf.convert_to_tensor(np.clip(fake_input, -1, 1))\n        \n    counter += 1\n\n","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"include_colab_link":true,"name":"Generative_Adversarial_Nets_Eager.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"}},"nbformat":4,"nbformat_minor":1}